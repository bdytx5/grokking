step 0: train loss 4.2874, val loss 4.2823
iter 0: loss 4.2675, time 36060.50ms, mfu -100.00%
iter 10: loss 3.2466, time 260.02ms, mfu 1.43%
iter 20: loss 2.7844, time 259.21ms, mfu 1.43%
iter 30: loss 2.6368, time 259.96ms, mfu 1.43%
iter 40: loss 2.5755, time 260.67ms, mfu 1.43%
iter 50: loss 2.5297, time 261.10ms, mfu 1.43%
iter 60: loss 2.5132, time 261.56ms, mfu 1.43%
iter 70: loss 2.4929, time 263.26ms, mfu 1.43%
iter 80: loss 2.4955, time 262.27ms, mfu 1.43%
iter 90: loss 2.4674, time 262.65ms, mfu 1.43%
iter 100: loss 2.4571, time 263.39ms, mfu 1.43%
iter 110: loss 2.4579, time 260.20ms, mfu 1.43%
iter 120: loss 2.4271, time 262.93ms, mfu 1.43%
iter 130: loss 2.4118, time 262.35ms, mfu 1.43%
iter 140: loss 2.4001, time 553.69ms, mfu 1.35%
iter 150: loss 2.4118, time 557.02ms, mfu 1.28%
iter 160: loss 2.3773, time 554.87ms, mfu 1.22%
iter 170: loss 2.3482, time 556.89ms, mfu 1.17%
iter 180: loss 2.3112, time 557.09ms, mfu 1.12%
iter 190: loss 2.2463, time 558.13ms, mfu 1.07%
iter 200: loss 2.2079, time 560.44ms, mfu 1.03%
iter 210: loss 2.1371, time 566.39ms, mfu 0.99%
iter 220: loss 2.1307, time 573.18ms, mfu 0.96%
iter 230: loss 2.0705, time 563.09ms, mfu 0.93%
iter 240: loss 2.0725, time 566.30ms, mfu 0.90%
step 250: train loss 1.9622, val loss 2.0657
saving checkpoint to out-shakespeare-char
iter 250: loss 2.0318, time 77569.55ms, mfu 0.81%
iter 260: loss 1.9746, time 580.48ms, mfu 0.80%
iter 270: loss 1.9684, time 573.07ms, mfu 0.78%
iter 280: loss 1.9703, time 576.66ms, mfu 0.77%
iter 290: loss 1.9128, time 587.39ms, mfu 0.75%
iter 300: loss 1.8943, time 573.35ms, mfu 0.74%
iter 310: loss 1.8646, time 573.27ms, mfu 0.73%
iter 320: loss 1.8454, time 580.90ms, mfu 0.73%
iter 330: loss 1.8172, time 576.95ms, mfu 0.72%
iter 340: loss 1.7755, time 573.72ms, mfu 0.71%
iter 350: loss 1.8283, time 577.60ms, mfu 0.70%
iter 360: loss 1.7728, time 573.53ms, mfu 0.70%
iter 370: loss 1.7388, time 578.84ms, mfu 0.69%
iter 380: loss 1.7289, time 583.13ms, mfu 0.69%
iter 390: loss 1.7283, time 575.08ms, mfu 0.68%
iter 400: loss 1.7668, time 587.87ms, mfu 0.68%
iter 410: loss 1.6975, time 590.00ms, mfu 0.67%
iter 420: loss 1.7150, time 576.71ms, mfu 0.67%
iter 430: loss 1.6919, time 582.99ms, mfu 0.67%
iter 440: loss 1.6570, time 589.60ms, mfu 0.66%
iter 450: loss 1.6565, time 584.12ms, mfu 0.66%
iter 460: loss 1.6100, time 582.94ms, mfu 0.66%
iter 470: loss 1.6594, time 578.19ms, mfu 0.66%
iter 480: loss 1.6230, time 579.99ms, mfu 0.66%
iter 490: loss 1.5988, time 584.27ms, mfu 0.65%
Traceback (most recent call last):
  File "/home/brett/Desktop/tutorials/grokking/nanoGPT/train.py", line 292, in <module>
    losses = estimate_loss()
  File "/home/brett/anaconda3/envs/grok2/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/brett/Desktop/tutorials/grokking/nanoGPT/train.py", line 251, in estimate_loss
    losses[k] = loss.item()
KeyboardInterrupt